{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTING LIBRARIES FOR CREATING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras_preprocessing\n",
    "from keras_preprocessing import image\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATING DATASETS FOR TRAINING AND VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1180 images belonging to 2 classes.\n",
      "Found 651 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_datagen = ImageDataGenerator(rescale = 1./255,horizontal_flip=True,rotation_range=45,height_shift_range=0.2,fill_mode='nearest')\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_generator = training_datagen.flow_from_directory(\"fire_dataset\",target_size=(224,224),class_mode='categorical',batch_size = 64)\n",
    "validation_generator = validation_datagen.flow_from_directory(\"Fire-Detection\",target_size=(224,224),class_mode='categorical',batch_size= 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATING INCEPTIONV3 MODEL FOR IMAGE RECOGNITION AND CLASSIFICATION OF FIRE AND NONE FIRE IMAGE.\n",
    "OUR MODEL CONTAINS 1 INPUT LAYER(GLOBALAVERAGEPOOLING2D), 3 DENSE LAYERS AND 3 DROPOUT AYERS AND 1 OUTPUT LAYER. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "14/14 [==============================] - 41s 3s/step - loss: 5.2174 - acc: 0.6105 - val_loss: 0.2786 - val_acc: 0.9152\n",
      "Epoch 2/20\n",
      "14/14 [==============================] - 40s 3s/step - loss: 0.4194 - acc: 0.8035 - val_loss: 0.2265 - val_acc: 0.9196\n",
      "Epoch 3/20\n",
      "14/14 [==============================] - 41s 3s/step - loss: 0.3227 - acc: 0.8627 - val_loss: 0.1529 - val_acc: 0.9688\n",
      "Epoch 4/20\n",
      "14/14 [==============================] - 41s 3s/step - loss: 0.2720 - acc: 0.8942 - val_loss: 0.1474 - val_acc: 0.9330\n",
      "Epoch 5/20\n",
      "14/14 [==============================] - 42s 3s/step - loss: 0.2359 - acc: 0.9151 - val_loss: 0.2006 - val_acc: 0.9107\n",
      "Epoch 6/20\n",
      "14/14 [==============================] - 44s 3s/step - loss: 0.2698 - acc: 0.8965 - val_loss: 0.1874 - val_acc: 0.9554\n",
      "Epoch 7/20\n",
      "14/14 [==============================] - 46s 3s/step - loss: 0.2474 - acc: 0.9058 - val_loss: 0.1505 - val_acc: 0.9420\n",
      "Epoch 8/20\n",
      "14/14 [==============================] - 46s 3s/step - loss: 0.2025 - acc: 0.9233 - val_loss: 0.4850 - val_acc: 0.8482\n",
      "Epoch 9/20\n",
      "14/14 [==============================] - 47s 3s/step - loss: 0.2186 - acc: 0.9330 - val_loss: 0.1393 - val_acc: 0.9509\n",
      "Epoch 10/20\n",
      "14/14 [==============================] - 47s 3s/step - loss: 0.2058 - acc: 0.9291 - val_loss: 0.2012 - val_acc: 0.9464\n",
      "Epoch 11/20\n",
      "14/14 [==============================] - 47s 3s/step - loss: 0.2173 - acc: 0.9174 - val_loss: 0.2117 - val_acc: 0.9375\n",
      "Epoch 12/20\n",
      "14/14 [==============================] - 48s 3s/step - loss: 0.1834 - acc: 0.9319 - val_loss: 0.2795 - val_acc: 0.9330\n",
      "Epoch 13/20\n",
      "14/14 [==============================] - 47s 3s/step - loss: 0.1720 - acc: 0.9477 - val_loss: 0.2538 - val_acc: 0.8750\n",
      "Epoch 14/20\n",
      "14/14 [==============================] - 46s 3s/step - loss: 0.1495 - acc: 0.9407 - val_loss: 0.2076 - val_acc: 0.9241\n",
      "Epoch 15/20\n",
      "14/14 [==============================] - 47s 3s/step - loss: 0.1709 - acc: 0.9475 - val_loss: 0.1876 - val_acc: 0.9554\n",
      "Epoch 16/20\n",
      "14/14 [==============================] - 46s 3s/step - loss: 0.1709 - acc: 0.9465 - val_loss: 0.3905 - val_acc: 0.8170\n",
      "Epoch 17/20\n",
      "14/14 [==============================] - 48s 3s/step - loss: 0.1891 - acc: 0.9386 - val_loss: 0.2049 - val_acc: 0.9375\n",
      "Epoch 18/20\n",
      "14/14 [==============================] - 47s 3s/step - loss: 0.1653 - acc: 0.9498 - val_loss: 0.2153 - val_acc: 0.9509\n",
      "Epoch 19/20\n",
      "14/14 [==============================] - 46s 3s/step - loss: 0.2002 - acc: 0.9372 - val_loss: 0.1927 - val_acc: 0.9509\n",
      "Epoch 20/20\n",
      "14/14 [==============================] - 46s 3s/step - loss: 0.1411 - acc: 0.9453 - val_loss: 0.1215 - val_acc: 0.9598\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 57s 4s/step - loss: 1.4686 - acc: 0.4709 - val_loss: 0.1251 - val_acc: 0.9330\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 53s 4s/step - loss: 0.8494 - acc: 0.5721 - val_loss: 0.1642 - val_acc: 0.9598\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 52s 4s/step - loss: 0.6161 - acc: 0.7058 - val_loss: 0.1516 - val_acc: 0.9643\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 54s 4s/step - loss: 0.4706 - acc: 0.8128 - val_loss: 0.2390 - val_acc: 0.9018\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 54s 4s/step - loss: 0.4529 - acc: 0.8581 - val_loss: 0.1883 - val_acc: 0.9152\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 53s 4s/step - loss: 0.4176 - acc: 0.8907 - val_loss: 0.2444 - val_acc: 0.8750\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 53s 4s/step - loss: 0.3941 - acc: 0.9244 - val_loss: 0.2610 - val_acc: 0.8616\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 54s 4s/step - loss: 0.3903 - acc: 0.9107 - val_loss: 0.2743 - val_acc: 0.8661\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 56s 4s/step - loss: 0.3712 - acc: 0.9118 - val_loss: 0.2625 - val_acc: 0.8750\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 55s 4s/step - loss: 0.3630 - acc: 0.9174 - val_loss: 0.2241 - val_acc: 0.8973\n"
     ]
    }
   ],
   "source": [
    "input_tensor = Input(shape=(224, 224, 3))\n",
    "base_model = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(2048, activation='relu')(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "predictions = Dense(2, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "for layer in base_model.layers:\n",
    "  layer.trainable = False\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "history = model.fit(train_generator,steps_per_epoch = 14,epochs = 20,validation_data = validation_generator,validation_steps = 14)\n",
    "\n",
    "#To train the top 2 inception blocks, freeze the first 249 layers and unfreeze the rest.\n",
    "for layer in model.layers[:249]:\n",
    "  layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "  layer.trainable = True\n",
    "#Recompile the model for these modifications to take effect\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(learning_rate=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['acc'])\n",
    "history = model.fit(train_generator,steps_per_epoch = 14,epochs = 10,validation_data = validation_generator,validation_steps = 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "APPLICATION OF OUR MODEL ON LIVE FEED."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fire\n",
      "chill hai\n",
      "chill hai\n",
      "chill hai\n",
      "chill hai\n",
      "chill hai\n",
      "chill hai\n",
      "chill hai\n",
      "chill hai\n",
      "chill hai\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from playsound import playsound\n",
    "from keras.preprocessing import image\n",
    "from twilio.rest import Client\n",
    "#Load the saved model\n",
    "video = cv2.VideoCapture(0)\n",
    "\n",
    "for i in range(10):\n",
    "        l=[]\n",
    "        for j in range(10):\n",
    "                _,frame = video.read()\n",
    "                im = Image.fromarray(frame,'RGB')\n",
    "                im = im.resize((224,224))\n",
    "                img_array = image.img_to_array(im)\n",
    "                img_array = np.expand_dims(img_array, axis=0) / 255\n",
    "                probabilities = model.predict(img_array)[0]\n",
    "                prediction = np.argmax(probabilities)\n",
    "                l.append(prediction)\n",
    "        #frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "        #if prediction == 0:\n",
    "                \n",
    "                #playsound('Fire alarm - 2018.mp3')\n",
    "                #print('playing sound using  playsound')\n",
    "        if l.count(1)<=2:\n",
    "                playsound('Fire alarm - 2018.mp3')\n",
    "                client = Client('ACe524474472b65c3c14d2d94a59e0b83c', 'c96c2963972f5868db82e7ac2bf3d53b')\n",
    "                message = client.calls.create(\n",
    "                     from_='+19704898322',\n",
    "                     to='+918368751110',\n",
    "                     url = 'https://api.twilio.com/2010-04-01/Accounts/ACe524474472b65c3c14d2d94a59e0b83c/Calls.json' )\n",
    "                \n",
    "                \n",
    "                \n",
    "                print('fire')\n",
    "                \n",
    "                \n",
    "                \n",
    "        else:\n",
    "                print('chill hai')\n",
    "        cv2.imshow(\"Capturing\", frame)\n",
    "        key=cv2.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "                break\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e1e75ddac2269c08fe69e3ddbb1cbe2523492437ad185b520d28cbde1c51c81f"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
